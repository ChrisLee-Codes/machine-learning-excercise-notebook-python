{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"logistic-regression.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"usDG-zMJWI20","colab_type":"text"},"cell_type":"markdown","source":["这是一个完整的用scipy.optimize.minimize训练的例子"]},{"metadata":{"id":"r3GaSVl9-TO5","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import optimize\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","\"\"\" X是训练集的数据 \"\"\"\n","X_train = np.array([[1.,  1.],\n","              [1.,  2.],\n","              [-1., -1.],\n","              [-1., -2.]])\n","\"\"\" y是训练集的label \"\"\"\n","y_train = np.array([1, 1, 0, 0])\n","\n","\"\"\" 处理训练集X，补上x_0 \"\"\"\n","X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n","\n","\"\"\"Sigmoid 函数公式 \"\"\"\n","def sigmoid(z):\n","  return 1/(1 + np.exp(-z))\n","\n","\"\"\" 目标函数，也就是待最小化的 Cost function \"\"\"\n","def cost(theta, X, y):\n","  first = - y.T @ np.log(sigmoid(X @ theta))\n","  second = (1 - y.T) @ np.log(1 - sigmoid(X @ theta))\n","  return ((first - second) / (len(X))).item()\n","\n","def hypothesis(X, theta):\n","  return sigmoid(X @ theta)\n","\n","def cost_wrapper(theta):\n","  return cost(theta, X_train, y_train)\n","\n","def hypothesis_wrapper(theta):\n","  return hypothesis(X_train, theta)\n","\n","\"\"\" 目标函数的梯度 \"\"\"\n","def gradient(theta):\n","  ret = (1/X_train.shape[0])*((hypothesis_wrapper(theta) - y_train).T @ X_train)\n","  return ret\n","\n","theta_train = np.array([1, 1.,2.])\n","\n","theta_opt = optimize.minimize(cost_wrapper, theta_train, method='CG', jac=gradient)\n","print(theta_opt)\n","\n","\"\"\" 构造预测集数据 \"\"\"\n","delta = 0.2\n","px = np.arange(-3.0, 3.0, delta)\n","py = np.arange(-3.0, 3.0, delta)\n","px, py = np.meshgrid(px, py)\n","px = px.reshape((px.size, 1))\n","py = py.reshape((py.size, 1))\n","pz = np.hstack((np.hstack((np.ones((px.size, 1)), px)), py))\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111, projection='3d')\n","ax.scatter(X_train[:, 1], X_train[:, 2], y_train, color='red', marker='^', s=200, label='Traning Data')  # plot训练集\n","ax.scatter(px, py, (hypothesis(pz, theta_opt.x)), color='gray', label='Prediction Data')  # plot预测集, 分类时加上 np.around\n","ax.legend(loc=2)\n","ax.set_xlabel('x')\n","ax.set_ylabel('y')\n","ax.set_zlabel('z')\n","ax.set_title('classification')\n","plt.show()"],"execution_count":0,"outputs":[]}]}